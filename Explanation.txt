##### 1. Streamlit #####
ğŸ“ Where it is used?
Used for building the user interface (UI) of the application.
Provides an interactive web-based platform for users to input URLs and ask questions.
ğŸ”¹ How it is used?
st.title() â†’ Displays the application title.
st.sidebar.text_input() â†’ Captures user input URLs.
st.button() â†’ Processes URLs when clicked.
st.write() and st.header() â†’ Displays results.
ğŸ¯ Purpose: Enables an easy-to-use UI for users without requiring frontend development.



#####2. OpenAI API (GPT)#####
ğŸ“ Where it is used?
Used in the question-answering step.
The GPT model generates answers based on retrieved documents.
ğŸ”¹ How it is used?
OpenAI(temperature=0.9, max_tokens=500) initializes the model.
The RetrievalQAWithSourcesChain retrieves relevant data and passes it to GPT for generating answers.
ğŸ¯ Purpose:Provides AI-powered natural language responses to user queries.

#####3. FAISS (Facebook AI Similarity Search)#####
ğŸ“ Where it is used?
Used to store and retrieve document embeddings efficiently.
ğŸ”¹ How it is used?
FAISS.from_documents(docs, embeddings) â†’ Creates a vector index from text chunks.
The index is saved as a .pkl file and loaded when answering queries.
ğŸ¯ Purpose:Enables fast similarity search for retrieving relevant document chunks.

#####4. LangChain#####
ğŸ“ Where it is used?
Used for handling text processing, retrieval, and LLM integration.
ğŸ”¹ How it is used?
RetrievalQAWithSourcesChain.from_llm() â†’ Connects OpenAI with FAISS for retrieval.
RecursiveCharacterTextSplitter â†’ Splits large text into chunks.
ğŸ¯ Purpose:Makes it easy to work with LLMs by managing context and retrieval.

#####5. UnstructuredURLLoader#####
ğŸ“ Where it is used?
Used to extract text from the given URLs.
ğŸ”¹ How it is used?
loader = UnstructuredURLLoader(urls=urls) â†’ Loads and extracts data.
data = loader.load() â†’ Fetches text from the provided URLs.
ğŸ¯ Purpose:Converts raw web content into usable text for further processing.

######6. RecursiveCharacterTextSplitter#####
ğŸ“ Where it is used?
Used to break long documents into smaller chunks.
ğŸ”¹ How it is used?
text_splitter.split_documents(data) â†’ Splits extracted text into smaller, meaningful pieces.
ğŸ¯ Purpose:Improves retrieval performance by handling long documents efficiently.


######7. OpenAIEmbeddings#####
ğŸ“ Where it is used?
Used to convert text chunks into numerical embeddings for similarity search.
ğŸ”¹ How it is used?
embeddings = OpenAIEmbeddings() initializes the embedding model.
FAISS uses these embeddings to retrieve relevant content.
ğŸ¯ Purpose:Transforms text into a searchable numerical format.


#####8. Pickle#####
ğŸ“ Where it is used?
Used to save and load the FAISS index.
ğŸ”¹ How it is used?
pickle.dump(vectorstore_openai, f) â†’ Saves the FAISS index to a file.
pickle.load(f) â†’ Loads the index when needed.
ğŸ¯ Purpose:Ensures that embeddings are saved and reused without reprocessing.

####9. dotenv#####
ğŸ“ Where it is used?
Loads the OpenAI API key from the environment.
ğŸ”¹ How it is used?
load_dotenv() reads environment variables.
ğŸ¯ Purpose:Keeps API keys secure by not hardcoding them in the script.

#####10. OS & Time Modules#####
ğŸ“ Where it is used?
OS: Used for file handling and checking FAISS index availability.
Time: Used to track processing stages.
ğŸ”¹ How it is used?
os.path.exists(file_path) â†’ Checks if the FAISS index is available.
time.sleep() â†’ Can be used to delay execution if needed.
ğŸ¯ Purpose:Handles file operations and process timing.



